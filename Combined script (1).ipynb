{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57018766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Training with 540 data points...\n",
      "Training with 2700 data points...\n",
      "Training with 5400 data points...\n",
      "Training with 11880 data points...\n",
      "Training with 450 data points...\n",
      "Training with 2250 data points...\n",
      "Training with 4500 data points...\n",
      "Training with 9900 data points...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "val_split = 0.1\n",
    "lr = 0.0005\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "\n",
    "# Datasets\n",
    "transform_mnist = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "transform_cifar = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
    "\n",
    "# Validation split\n",
    "def split_data(dataset, val_split=0.1):\n",
    "    train_size = int((1 - val_split) * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    return train_set, val_set\n",
    "\n",
    "mnist_train_set, mnist_val_set = split_data(mnist_train)\n",
    "cifar_train_set, cifar_val_set = split_data(cifar_train)\n",
    "\n",
    "# DataLoader\n",
    "def get_loader(dataset, batch_size, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "mnist_val_loader = get_loader(mnist_val_set, batch_size=1024, shuffle=False)\n",
    "cifar_val_loader = get_loader(cifar_val_set, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Model Setup\n",
    "def get_model(dataset_name):\n",
    "    if dataset_name == 'mnist':\n",
    "        model = torchvision.models.resnet18(pretrained=False)\n",
    "        model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    elif dataset_name == 'cifar':\n",
    "        model = torchvision.models.resnet18(pretrained=False)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    return model\n",
    "\n",
    "# Training and Validation\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Experiment for Data Scaling\n",
    "def data_scaling_experiment(train_dataset, val_loader, dataset_name):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    if device.type == 'cuda':\n",
    "        torch.cuda.set_per_process_memory_fraction(0.8)\n",
    "    data_sizes = [0.01, 0.05, 0.1, 0.22]\n",
    "    accuracies = []\n",
    "\n",
    "    for size in data_sizes:\n",
    "        subset_size = int(size * len(train_dataset))\n",
    "        train_subset, _ = torch.utils.data.random_split(train_dataset, [subset_size, len(train_dataset) - subset_size])\n",
    "        train_loader = get_loader(train_subset, batch_size=batch_size)\n",
    "\n",
    "        model = get_model(dataset_name)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        print(f\"Training with {subset_size} data points...\")\n",
    "        accuracy = train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    return data_sizes, accuracies\n",
    "\n",
    "# Run Experiments\n",
    "mnist_sizes, mnist_accuracies = data_scaling_experiment(mnist_train_set, mnist_val_loader, 'mnist')\n",
    "cifar_sizes, cifar_accuracies = data_scaling_experiment(cifar_train_set, cifar_val_loader, 'cifar')\n",
    "\n",
    "#%%\n",
    "# Plot Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot([s * len(mnist_train_set) for s in mnist_sizes], mnist_accuracies, label='MNIST')\n",
    "plt.plot([s * len(cifar_train_set) for s in cifar_sizes], cifar_accuracies, label='CIFAR-10')\n",
    "plt.xlabel('Number of Labeled Data Points', fontsize=15)\n",
    "plt.ylabel('Validation Accuracy (%)', fontsize=15)\n",
    "plt.title('Accuracy vs. Labeled Data Points')\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22826d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 2080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # Returns True if GPU is available\n",
    "print(torch.cuda.get_device_name(0))  # Prints the name of the GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662daf3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Python\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      " 11%|█         | 11/100 [00:02<00:34,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 88.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:05<00:29,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Accuracy: 89.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [00:08<00:25,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Accuracy: 89.87%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:10<00:22,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Accuracy: 89.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:13<00:18,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Accuracy: 89.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:15<00:14,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Accuracy: 90.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:18<00:10,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Accuracy: 90.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:20<00:07,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Accuracy: 90.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [00:23<00:03,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Accuracy: 90.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:25<00:00,  3.86it/s]\n",
      "  1%|          | 7/836 [00:00<00:11, 69.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Accuracy: 90.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 836/836 [00:12<00:00, 69.58it/s]\n",
      "<ipython-input-3-84e47a20a3f5>:139: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  predictions = torch.tensor(predictions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2673 images to training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:10<01:58,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 97.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:21<01:41,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Accuracy: 97.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:31<01:28,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Accuracy: 97.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:42<01:15,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Accuracy: 97.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:52<01:02,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Accuracy: 97.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [01:02<00:49,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Accuracy: 98.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [01:13<00:37,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Accuracy: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [01:23<00:25,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Accuracy: 98.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [01:34<00:12,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Accuracy: 98.48%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:44<00:00,  1.05s/it]\n",
      "  1%|          | 8/794 [00:00<00:10, 71.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Accuracy: 96.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 794/794 [00:11<00:00, 72.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2539 images to training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:17<02:58,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:35<02:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Accuracy: 98.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:53<02:18,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30, Accuracy: 98.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [01:10<01:59,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40, Accuracy: 99.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [01:28<01:39,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50, Accuracy: 98.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [01:46<01:19,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60, Accuracy: 98.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [02:04<00:59,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70, Accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [02:21<00:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80, Accuracy: 99.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [02:39<00:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90, Accuracy: 98.53%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:57<00:00,  1.78s/it]\n",
      "  1%|          | 8/754 [00:00<00:10, 71.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100, Accuracy: 98.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 754/754 [00:10<00:00, 70.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 2412 images to training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [00:25<04:11,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Accuracy: 98.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:51<03:38,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20, Accuracy: 98.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [01:01<03:14,  2.56s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-84e47a20a3f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    156\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_last\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_parameters\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Reset the model each iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m     \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m     \u001b[0mdatapoint_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[0maccuracy_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-84e47a20a3f5>\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, device, num_epochs, val_interval)\u001b[0m\n\u001b[0;32m    116\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mval_interval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    482\u001b[0m                             )\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"differentiable\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"betas\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             has_complex = self._init_group(\n\u001b[0m\u001b[0;32m    217\u001b[0m                 \u001b[0mgroup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Python\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_init_group\u001b[1;34m(self, group, params_with_grad, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"params\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[0mhas_complex\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "if __name__ == \"__main__\" and \"ipykernel\" not in sys.argv[0]:\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"-d\", \"--debug\", action='store_true', help=\"Debug mode\")\n",
    "    args = ap.parse_args()\n",
    "else:\n",
    "    # Default argument handling for Jupyter\n",
    "    class Args:\n",
    "        debug = False\n",
    "    args = Args()\n",
    "    \n",
    "### Hyperparameters\n",
    "val_split = 0.1\n",
    "unlabelled_size = 0.99\n",
    "lr = 0.0005\n",
    "batch_size = 64\n",
    "num_epochs = 100\n",
    "label_iterations = 20\n",
    "top_frac = 0.05\n",
    "\n",
    "### Setup MNIST dataset\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "debug = args.debug\n",
    "if debug:\n",
    "    train_dataset.data = train_dataset.data[:1000]\n",
    "    train_dataset.targets = train_dataset.targets[:1000]\n",
    "    \n",
    "    torch.set_num_threads(4)\n",
    "val_dataset = deepcopy(train_dataset)\n",
    "\n",
    "train_size = int((1 - val_split) * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "indexes = torch.randperm(len(train_dataset)).tolist()\n",
    "# Define validation set\n",
    "indexes_val = indexes[train_size:]\n",
    "val_dataset.targets = val_dataset.targets[indexes_val]\n",
    "val_dataset.data = val_dataset.data[indexes_val]\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Define training set\n",
    "indexes_train = indexes[:train_size]\n",
    "train_dataset.targets = train_dataset.targets[indexes_train]\n",
    "train_dataset.data = train_dataset.data[indexes_train]\n",
    "\n",
    "# Split training data into labelled and unlabelled\n",
    "unlabelled_size = int(unlabelled_size * len(train_dataset))\n",
    "indexes_train = torch.randperm(len(train_dataset)).tolist()  # Redefine indexes_train\n",
    "unlabbelled_dataset = deepcopy(train_dataset)\n",
    "unlabbelled_dataset.targets = unlabbelled_dataset.targets[indexes_train[:unlabelled_size]]\n",
    "unlabbelled_dataset.data = unlabbelled_dataset.data[indexes_train[:unlabelled_size]]\n",
    "train_dataset.targets = train_dataset.targets[indexes_train[unlabelled_size:]]\n",
    "train_dataset.data = train_dataset.data[indexes_train[unlabelled_size:]]\n",
    "unlabbelled_dataset.targets = unlabbelled_dataset.targets\n",
    "unlabbelled_dataset.data = unlabbelled_dataset.data\n",
    "start_train_dataset = deepcopy(train_dataset)  # Save for baseline\n",
    "start_unlabbelled_dataset = deepcopy(unlabbelled_dataset)  # Save for baseline\n",
    "\n",
    "\n",
    "def transfer_unlabelled_to_labeled(unlabbelled_dataset, train_dataset, indexes):\n",
    "    # Convert indexes to boolean mask\n",
    "    indexes = torch.tensor([i in indexes for i in range(len(unlabbelled_dataset.targets))])\n",
    "    \n",
    "    train_dataset.targets = torch.cat([train_dataset.targets, unlabbelled_dataset.targets[indexes]])\n",
    "    train_dataset.data = torch.cat([train_dataset.data, unlabbelled_dataset.data[indexes]])\n",
    "    unlabbelled_dataset.targets = unlabbelled_dataset.targets[~indexes]\n",
    "    unlabbelled_dataset.data = unlabbelled_dataset.data[~indexes]\n",
    "\n",
    "    return train_dataset, unlabbelled_dataset\n",
    "\n",
    "def validate_model(model, val_loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Setup model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "# Modify input layer to accept 1 channel\n",
    "model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "model_parameters = deepcopy(model.state_dict())\n",
    "model = model.to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10, val_interval=1):\n",
    "    accuracies = []\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            val_accuracy = validate_model(model, val_loader, device)\n",
    "            accuracies.append(val_accuracy)\n",
    "            print(f'Epoch {epoch + 1}, Accuracy: {val_accuracy:.2f}%')\n",
    "    return accuracies\n",
    "\n",
    "\n",
    "def label_iteration(model, train_dataset, unlabelled_dataset, device, top_frac=0.01):\n",
    "    # Use model to label all images in validation set\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    unlabelled_loader = torch.utils.data.DataLoader(unlabelled_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, _ in tqdm(unlabelled_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).softmax(dim=1)\n",
    "            predictions.extend(outputs.detach().cpu().numpy())\n",
    "\n",
    "    predictions = torch.tensor(predictions)\n",
    "    # Find top % of images with lowest top-confidence\n",
    "    top_percent = int(top_frac * len(predictions))\n",
    "    _, top_indices = predictions.max(-1)[0].topk(top_percent, largest=False)\n",
    "    print(f\"Adding {len(top_indices)} images to training set\")\n",
    "    train_dataset, unlabelled_dataset = transfer_unlabelled_to_labeled(unlabelled_dataset, train_dataset, top_indices)\n",
    "    \n",
    "    return train_dataset, unlabelled_dataset\n",
    "\n",
    "\n",
    "## Run active learning\n",
    "datapoint_list = []\n",
    "accuracy_list = []\n",
    "\n",
    "max_data_points =10000\n",
    "\n",
    "for i in range(label_iterations):\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    model.load_state_dict(model_parameters)  # Reset the model each iteration\n",
    "    accuracies = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, val_interval=10)\n",
    "    datapoint_list.append(len(train_dataset))\n",
    "    accuracy_list.append(accuracies)\n",
    "\n",
    "    # Stop if the labeled dataset reaches the maximum size\n",
    "    if len(train_dataset) >= max_data_points:\n",
    "        print(f\"Reached {max_data_points} labeled data points. Stopping active learning.\")\n",
    "        break\n",
    "\n",
    "    # Add new labeled data using active learning\n",
    "    if i < label_iterations - 1:\n",
    "        train_dataset, unlabbelled_dataset = label_iteration(model, train_dataset, unlabbelled_dataset, device, top_frac=top_frac)\n",
    "    \n",
    "# Add baseline accuracy (no active learning)\n",
    "n_datapoints = len(train_dataset) - len(start_train_dataset)\n",
    "model.load_state_dict(model_parameters)\n",
    "# We reuse the initial training set to reduce run to run variance\n",
    "train_dataset.data = torch.cat([start_train_dataset.data, start_unlabbelled_dataset.data[:n_datapoints]])\n",
    "train_dataset.targets = torch.cat([start_train_dataset.targets, start_unlabbelled_dataset.targets[:n_datapoints]])\n",
    "\n",
    "# Train model\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1024, shuffle=False)\n",
    "baseline_accuracy = train_model(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=num_epochs, val_interval=10)\n",
    "\n",
    "#%%\n",
    "def get_dat(datapoints, accuracies):\n",
    "    datapoints = np.array(datapoint_list)\n",
    "    accuracies = np.array(accuracy_list).max(-1)  # Max accuracy for each iteration\n",
    "\n",
    "    # Return the processed arrays\n",
    "    return datapoints, accuracies\n",
    "\n",
    "\n",
    "# Plot the accuracy\n",
    "datapoints = np.array(datapoint_list)\n",
    "accuracies = np.array(accuracy_list).max(-1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(datapoints, accuracies, label='AL Accuracy')\n",
    "plt.hlines(max(baseline_accuracy), min(datapoints), max(datapoints), label='Baseline Accuracy', color='red')\n",
    "plt.xlabel('Datapoints')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figs/accuracy.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1893dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datapoint_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-447dc3bde708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Example Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Replace these with actual datapoints and accuracy values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdatapoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatapoint_list\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# From Active Learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# From Active Learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#baseline_accuracy = max(baseline_accuracy)  # Baseline accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'datapoint_list' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example Data\n",
    "# Replace these with actual datapoints and accuracy values\n",
    "datapoints = np.array(datapoint_list)  # From Active Learning\n",
    "accuracies = np.array(accuracy_list).max(-1)  # From Active Learning\n",
    "#baseline_accuracy = max(baseline_accuracy)  # Baseline accuracy\n",
    "mnist_sizes = [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "mnist_accuracies = [85, 90, 93, 94, 95, 96]  # Replace with actual MNIST values\n",
    "cifar_sizes = [0.01, 0.05, 0.1, 0.2, 0.5, 1.0]\n",
    "cifar_accuracies = [50, 55, 60, 65, 70, 75]  # Replace with actual CIFAR-10 values\n",
    "\n",
    "# Combine Plots\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# MNIST and CIFAR-10 Accuracy\n",
    "plt.plot([s * len(mnist_train_set) for s in mnist_sizes], mnist_accuracies, label='MNIST Accuracy', linewidth = 3, color = 'r')\n",
    "plt.plot([s * len(cifar_train_set) for s in cifar_sizes], cifar_accuracies, label='CIFAR-10 Accuracy', linewidth =3, color = 'b')\n",
    "plt.plot([s * len(mnist_train_set) for s in mnist_sizes], mnist_accuracies, 'o', color ='firebrick', markersize = 10)\n",
    "plt.plot([s * len(cifar_train_set) for s in cifar_sizes], cifar_accuracies, 'v', color = 'dodgerblue', markersize = 10)\n",
    "\n",
    "\n",
    "\n",
    "# Active Learning and Baseline\n",
    "#plt.plot(datapoints, accuracies, label='MNIST - AL Accuracy', linestyle='--', linewidth = 3, color = 'g')\n",
    "#plt.hlines(xmin = 500, xmax = 10000, y = 32.39, linestyle='--', linewidth = 3, color = 'y', label ='CIFAR-10 - Baseline accuracy')\n",
    "#plt.hlines(baseline_accuracy, min(datapoints), 55000, colors='red', linestyles='dotted', label='MNIST - Baseline Accuracy', color = 'k')\n",
    "\n",
    "#plt.plot(cifar_al_datapoints, cifar_al_accuracies, label='CIFAR-10 AL Accuracy', linestyle='--', color='blue')\n",
    "\n",
    "# Plot Aesthetics\n",
    "plt.xlabel('Number of Labeled Data Points', fontsize=17)\n",
    "plt.ylabel('Validation Accuracy (%)', fontsize=17)\n",
    "plt.title('Accuracy Comparison Across AL, Baseline, MNIST, and CIFAR-10', fontsize=16)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(fontsize=20)\n",
    "plt.legend(prop = {'size':12})\n",
    "plt.grid()\n",
    "plt.xlim(0, 10000)\n",
    "plt.ylim(0, 110)\n",
    "\n",
    "# Save and Show\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f4cef29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Python\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Data Points: 1000, Accuracy: 93.35%\n",
      "Labeled Data Points: 2000, Accuracy: 95.77%\n",
      "Labeled Data Points: 3000, Accuracy: 96.95%\n",
      "Labeled Data Points: 4000, Accuracy: 97.35%\n",
      "Labeled Data Points: 5000, Accuracy: 98.35%\n",
      "Labeled Data Points: 6000, Accuracy: 96.90%\n",
      "Labeled Data Points: 7000, Accuracy: 98.63%\n",
      "Labeled Data Points: 8000, Accuracy: 98.33%\n",
      "Labeled Data Points: 9000, Accuracy: 98.15%\n",
      "Labeled Data Points: 1000, Accuracy: 86.13%\n",
      "Labeled Data Points: 2000, Accuracy: 94.27%\n",
      "Labeled Data Points: 3000, Accuracy: 96.93%\n",
      "Labeled Data Points: 4000, Accuracy: 97.65%\n",
      "Labeled Data Points: 5000, Accuracy: 97.47%\n",
      "Labeled Data Points: 6000, Accuracy: 98.57%\n",
      "Labeled Data Points: 7000, Accuracy: 97.28%\n",
      "Labeled Data Points: 8000, Accuracy: 98.70%\n",
      "Labeled Data Points: 9000, Accuracy: 97.82%\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Baseline_ACC'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-14718c2cdaa3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    189\u001b[0m        }\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mBaseline_ACC\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_dat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[0mget_dat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Baseline_ACC'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Nov 18 14:31:35 2024\n",
    "\n",
    "@author: vicly\n",
    "\"\"\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Hyperparameters\n",
    "val_split = 0.1\n",
    "lr = 0.0005\n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "step_size = 1000  # Number of samples added per active learning iteration\n",
    "\n",
    "# Datasets\n",
    "transform_mnist = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "transform_cifar = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "mnist_train = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_mnist)\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
    "\n",
    "# Validation split\n",
    "def split_data(dataset, val_split=0.1):\n",
    "    train_size = int((1 - val_split) * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_set, val_set = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "    return train_set, val_set\n",
    "\n",
    "mnist_train_set, mnist_val_set = split_data(mnist_train)\n",
    "cifar_train_set, cifar_val_set = split_data(cifar_train)\n",
    "\n",
    "# DataLoader\n",
    "def get_loader(dataset, batch_size, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "mnist_val_loader = get_loader(mnist_val_set, batch_size=1024, shuffle=False)\n",
    "cifar_val_loader = get_loader(cifar_val_set, batch_size=1024, shuffle=False)\n",
    "\n",
    "# Model Setup\n",
    "def get_model(dataset_name):\n",
    "    if dataset_name == 'mnist':\n",
    "        model = torchvision.models.resnet18(pretrained=False)\n",
    "        model.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    elif dataset_name == 'cifar':\n",
    "        model = torchvision.models.resnet18(pretrained=False)\n",
    "        model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    return model\n",
    "\n",
    "# Training and Validation\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Active Learning Functions\n",
    "def uncertainty_sampling(model, unlabeled_loader, device, top_n):\n",
    "    model.eval()\n",
    "    uncertainties = []\n",
    "    indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, _) in enumerate(unlabeled_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).softmax(dim=1)\n",
    "            max_probs, _ = outputs.max(dim=1)\n",
    "            uncertainty = 1 - max_probs  # Least confidence\n",
    "            uncertainties.extend(uncertainty.cpu().numpy())\n",
    "            indices.extend(range(batch_idx * len(images), (batch_idx + 1) * len(images)))\n",
    "\n",
    "    # Select top N uncertain samples\n",
    "    uncertainties = np.array(uncertainties)\n",
    "    top_indices = np.argsort(-uncertainties)[:top_n]\n",
    "    return np.array(indices)[top_indices]\n",
    "\n",
    "def margin_sampling(model, unlabeled_loader, device, top_n):\n",
    "    model.eval()\n",
    "    margins = []\n",
    "    indices = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, _) in enumerate(unlabeled_loader):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images).softmax(dim=1)\n",
    "            top2_probs = torch.topk(outputs, 2, dim=1).values\n",
    "            margin = top2_probs[:, 0] - top2_probs[:, 1]\n",
    "            margins.extend(margin.cpu().numpy())\n",
    "            indices.extend(range(batch_idx * len(images), (batch_idx + 1) * len(images)))\n",
    "\n",
    "    # Select top N smallest margin samples\n",
    "    margins = np.array(margins)\n",
    "    top_indices = np.argsort(margins)[:top_n]\n",
    "    return np.array(indices)[top_indices]\n",
    "\n",
    "# Main Active Learning Loop\n",
    "def active_learning_experiment(initial_size, total_size, dataset, val_loader, dataset_name, strategy='uncertainty', step_size=1000):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Initial labeled and unlabeled datasets\n",
    "    labeled_indices = np.random.choice(len(dataset), initial_size, replace=False)\n",
    "    unlabeled_indices = np.setdiff1d(np.arange(len(dataset)), labeled_indices)\n",
    "    labeled_dataset = torch.utils.data.Subset(dataset, labeled_indices)\n",
    "    unlabeled_dataset = torch.utils.data.Subset(dataset, unlabeled_indices)\n",
    "    \n",
    "    labeled_loader = get_loader(labeled_dataset, batch_size=batch_size)\n",
    "    unlabeled_loader = get_loader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    accuracies = []\n",
    "    sizes = []\n",
    "\n",
    "    while len(labeled_dataset) < total_size:\n",
    "        # Train model on the current labeled set\n",
    "        model = get_model(dataset_name)\n",
    "        model.to(device)\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        accuracy = train_and_validate(model, labeled_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "        accuracies.append(accuracy)\n",
    "        sizes.append(len(labeled_dataset))\n",
    "\n",
    "        print(f\"Labeled Data Points: {len(labeled_dataset)}, Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "        # Exit if we reach the total size\n",
    "        if len(labeled_dataset) + step_size > total_size:\n",
    "            break\n",
    "\n",
    "        # Select new samples\n",
    "        if strategy == 'uncertainty':\n",
    "            top_indices = uncertainty_sampling(model, unlabeled_loader, device, step_size)\n",
    "        elif strategy == 'margin':\n",
    "            top_indices = margin_sampling(model, unlabeled_loader, device, step_size)\n",
    "\n",
    "        # Add selected samples to the labeled dataset\n",
    "        labeled_indices = np.concatenate([labeled_indices, unlabeled_indices[top_indices]])\n",
    "        unlabeled_indices = np.setdiff1d(unlabeled_indices, unlabeled_indices[top_indices])\n",
    "        labeled_dataset = torch.utils.data.Subset(dataset, labeled_indices)\n",
    "        unlabeled_dataset = torch.utils.data.Subset(dataset, unlabeled_indices)\n",
    "\n",
    "        labeled_loader = get_loader(labeled_dataset, batch_size=batch_size)\n",
    "        unlabeled_loader = get_loader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return sizes, accuracies\n",
    "\n",
    "# Run Active Learning Experiment\n",
    "mnist_sizes_uncertainty, mnist_accuracies_uncertainty = active_learning_experiment(\n",
    "    initial_size=1000, total_size=10000, dataset=mnist_train_set, val_loader=mnist_val_loader, dataset_name='mnist', strategy='uncertainty'\n",
    ")\n",
    "\n",
    "mnist_sizes_margin, mnist_accuracies_margin = active_learning_experiment(\n",
    "    initial_size=1000, total_size=10000, dataset=mnist_train_set, val_loader=mnist_val_loader, dataset_name='mnist', strategy='margin'\n",
    ")\n",
    "\n",
    "\n",
    "# Plot Results\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mnist_sizes_uncertainty, mnist_accuracies_uncertainty, label='Uncertainty Sampling', linewidth = 3)\n",
    "plt.plot(mnist_sizes_margin, mnist_accuracies_margin, label='Margin Sampling', linewidth = 3)\n",
    "plt.plot(mnist_sizes_uncertainty, mnist_accuracies_uncertainty, 'v', color = 'dodgerblue', markersize = 10)\n",
    "plt.plot(mnist_sizes_margin, mnist_accuracies_margin, 'o', color ='darkorange', markersize = 10)\n",
    "plt.xlabel('Uncertainty Sampling', fontsize = 15)\n",
    "plt.ylabel(\"Intensity /a.u.\", fontsize = 15)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "\n",
    "plt.plot(datapoints, accuracies, label='AL Accuracy')\n",
    "plt.hlines(max(baseline_accuracy), min(datapoints), max(datapoints), label='Baseline Accuracy', color='red')\n",
    "\n",
    "plt.title(label = 'Active learning - MNIST', fontsize = 40)\n",
    "plt.xlabel('Number of Labeled Data Points')\n",
    "plt.ylabel('Validation Accuracy (%)')\n",
    "plt.title('Active Learning Strategies - MNIST')\n",
    "plt.legend(prop = {'size':12})\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ded55d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Python\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Python\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Training: 100%|██████████| 10/10 [00:26<00:00,  2.60s/it]\n",
      "Training: 100%|██████████| 10/10 [00:01<00:00,  7.43it/s]\n",
      "Training: 100%|██████████| 10/10 [00:02<00:00,  3.84it/s]\n",
      "Training: 100%|██████████| 10/10 [00:03<00:00,  2.58it/s]\n",
      "Training: 100%|██████████| 10/10 [00:05<00:00,  1.92it/s]\n",
      "Training: 100%|██████████| 10/10 [00:06<00:00,  1.54it/s]\n",
      "Training: 100%|██████████| 10/10 [00:07<00:00,  1.29it/s]\n",
      "Training: 100%|██████████| 10/10 [00:09<00:00,  1.10it/s]\n",
      "Training: 100%|██████████| 10/10 [00:10<00:00,  1.03s/it]\n",
      "Training: 100%|██████████| 10/10 [00:11<00:00,  1.17s/it]\n",
      "Training: 100%|██████████| 10/10 [00:12<00:00,  1.30s/it]\n",
      "Training: 100%|██████████| 10/10 [00:14<00:00,  1.42s/it]\n",
      "Training: 100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n",
      "Training: 100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n",
      "Training: 100%|██████████| 10/10 [00:18<00:00,  1.80s/it]\n",
      "Training: 100%|██████████| 10/10 [00:19<00:00,  1.93s/it]\n",
      "Training: 100%|██████████| 10/10 [00:20<00:00,  2.05s/it]\n",
      "Training: 100%|██████████| 10/10 [00:22<00:00,  2.21s/it]\n",
      "Training: 100%|██████████| 10/10 [00:23<00:00,  2.39s/it]\n",
      "Training: 100%|██████████| 10/10 [00:25<00:00,  2.56s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- Hyperparameters ----\n",
    "batch_size = 128  # Larger batch size for faster processing\n",
    "lr = 0.001  # Learning rate\n",
    "num_epochs = 10  # Fewer epochs to speed up training\n",
    "initial_size = 500  # Initial labeled dataset size\n",
    "max_datapoints = 10000  # Max labeled dataset size\n",
    "points_per_step = 500  # Points added in each AL iteration\n",
    "\n",
    "# ---- Dataset Transforms ----\n",
    "cifar_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# ---- Load CIFAR-10 Dataset ----\n",
    "cifar_train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=cifar_transform)\n",
    "cifar_val = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=cifar_transform)\n",
    "\n",
    "# ---- DataLoader Helper ----\n",
    "def get_loader(dataset, batch_size, shuffle=True):\n",
    "    return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "cifar_val_loader = get_loader(cifar_val, batch_size, shuffle=False)\n",
    "\n",
    "# ---- Model Initialization ----\n",
    "def get_model():\n",
    "    model = torchvision.models.resnet18(pretrained=False)\n",
    "    model.fc = torch.nn.Linear(model.fc.in_features, 10)\n",
    "    return model\n",
    "\n",
    "# ---- Training and Validation ----\n",
    "def train_and_validate(model, train_loader, val_loader, criterion, optimizer, device, num_epochs):\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# ---- Baseline Accuracy ----\n",
    "def baseline_accuracy(train_set, val_loader, dataset_size):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = get_model()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    labeled_indices = np.random.choice(len(train_set), dataset_size, replace=False)\n",
    "    labeled_set = torch.utils.data.Subset(train_set, labeled_indices)\n",
    "    labeled_loader = get_loader(labeled_set, batch_size)\n",
    "\n",
    "    return train_and_validate(model, labeled_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# ---- Active Learning Loop ----\n",
    "def active_learning_accuracy(train_set, val_loader, initial_size, max_datapoints, points_per_step):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = get_model()\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Initialize labeled and unlabeled indices\n",
    "    labeled_indices = np.random.choice(len(train_set), initial_size, replace=False)\n",
    "    unlabeled_indices = np.setdiff1d(np.arange(len(train_set)), labeled_indices)\n",
    "\n",
    "    labeled_set = torch.utils.data.Subset(train_set, labeled_indices)\n",
    "    labeled_loader = get_loader(labeled_set, batch_size)\n",
    "\n",
    "    datapoints, accuracies = [], []\n",
    "    while len(labeled_indices) < max_datapoints:\n",
    "        # Train and validate\n",
    "        accuracy = train_and_validate(model, labeled_loader, val_loader, criterion, optimizer, device, num_epochs)\n",
    "        accuracies.append(accuracy)\n",
    "        datapoints.append(len(labeled_indices))\n",
    "\n",
    "        if len(labeled_indices) + points_per_step > max_datapoints:\n",
    "            points_per_step = max_datapoints - len(labeled_indices)\n",
    "\n",
    "        # Model evaluation for uncertainty sampling\n",
    "        model.eval()\n",
    "        uncertainties = []\n",
    "        global_indices = []\n",
    "        with torch.no_grad():\n",
    "            # Process the entire unlabeled dataset in batches\n",
    "            unlabeled_loader = get_loader(torch.utils.data.Subset(train_set, unlabeled_indices), batch_size, shuffle=False)\n",
    "            for batch_idx, (images, _) in enumerate(unlabeled_loader):\n",
    "                images = images.to(device)\n",
    "                outputs = model(images).softmax(dim=1)\n",
    "                max_probs, _ = outputs.max(dim=1)\n",
    "                uncertainties.extend(1 - max_probs.cpu().numpy())\n",
    "                global_indices.extend(unlabeled_indices[batch_idx * batch_size : batch_idx * batch_size + len(images)])\n",
    "\n",
    "        # Sort uncertainties and pick the most uncertain samples\n",
    "        uncertainties = np.array(uncertainties)\n",
    "        sorted_indices = np.argsort(-uncertainties)\n",
    "        num_to_add = min(points_per_step, len(global_indices))\n",
    "        new_indices = np.array(global_indices)[sorted_indices[:num_to_add]]\n",
    "\n",
    "        # Update labeled and unlabeled indices\n",
    "        labeled_indices = np.concatenate([labeled_indices, new_indices])\n",
    "        unlabeled_indices = np.setdiff1d(unlabeled_indices, new_indices)\n",
    "        labeled_set = torch.utils.data.Subset(train_set, labeled_indices)\n",
    "        labeled_loader = get_loader(labeled_set, batch_size)\n",
    "\n",
    "    return datapoints, accuracies\n",
    "\n",
    "# ---- Run CIFAR-10 Experiments ----\n",
    "# Baseline Accuracy\n",
    "cifar_baseline = baseline_accuracy(cifar_train, cifar_val_loader, dataset_size=10000)\n",
    "\n",
    "# Active Learning Accuracy\n",
    "cifar_al_datapoints, cifar_al_accuracies = active_learning_accuracy(\n",
    "    cifar_train, cifar_val_loader, initial_size=initial_size, max_datapoints=max_datapoints, points_per_step=points_per_step\n",
    ")\n",
    "\n",
    "# ---- Plot Results ----\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(cifar_al_datapoints, cifar_al_accuracies, label='CIFAR-10 AL Accuracy', linestyle='--', color='blue', marker='o')\n",
    "plt.axhline(y=cifar_baseline, color='red', linestyle='dotted', label='Baseline Accuracy')\n",
    "plt.xlabel('Number of Labeled Data Points', fontsize=14)\n",
    "plt.ylabel('Validation Accuracy (%)', fontsize=14)\n",
    "plt.title('CIFAR-10: AL Accuracy vs Baseline', fontsize=16)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681fdca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
